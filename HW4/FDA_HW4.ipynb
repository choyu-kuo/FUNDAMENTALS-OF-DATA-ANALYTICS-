{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDA_HW4\n",
    "#### E94041220 郭濯瑀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, metrics, model_selection\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature 描述\n",
    "\n",
    "* Attribute 1 : Unique user id \n",
    "* Attribute 2 : Average ratings on churches \n",
    "* Attribute 3 : Average ratings on resorts \n",
    "* Attribute 4 : Average ratings on beaches \n",
    "* Attribute 5 : Average ratings on parks \n",
    "* Attribute 6 : Average ratings on theatres \n",
    "* Attribute 7 : Average ratings on museums \n",
    "* Attribute 8 : Average ratings on malls \n",
    "* Attribute 9 : Average ratings on zoo \n",
    "* Attribute 10 : Average ratings on restaurants \n",
    "* Attribute 11 : Average ratings on pubs/bars \n",
    "* Attribute 12 : Average ratings on local services \n",
    "* Attribute 13 : Average ratings on burger/pizza shops \n",
    "* Attribute 14 : Average ratings on hotels/other lodgings \n",
    "* Attribute 15 : Average ratings on juice bars \n",
    "* Attribute 16 : Average ratings on art galleries \n",
    "* Attribute 17 : Average ratings on dance clubs \n",
    "* Attribute 18 : Average ratings on swimming pools \n",
    "* Attribute 19 : Average ratings on gyms \n",
    "* Attribute 20 : Average ratings on bakeries \n",
    "* Attribute 21 : Average ratings on beauty & spas \n",
    "* Attribute 22 : Average ratings on cafes \n",
    "* Attribute 23 : Average ratings on view points \n",
    "* Attribute 24 : Average ratings on monuments \n",
    "* Attribute 25 : Average ratings on gardens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Category 1</th>\n",
       "      <th>Category 2</th>\n",
       "      <th>Category 3</th>\n",
       "      <th>Category 4</th>\n",
       "      <th>Category 5</th>\n",
       "      <th>Category 6</th>\n",
       "      <th>Category 7</th>\n",
       "      <th>Category 8</th>\n",
       "      <th>Category 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Category 16</th>\n",
       "      <th>Category 17</th>\n",
       "      <th>Category 18</th>\n",
       "      <th>Category 19</th>\n",
       "      <th>Category 20</th>\n",
       "      <th>Category 21</th>\n",
       "      <th>Category 22</th>\n",
       "      <th>Category 23</th>\n",
       "      <th>Category 24</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.65</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.65</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User 3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.63</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>User 4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.63</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User 5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.63</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     User  Category 1  Category 2  Category 3  Category 4  Category 5  \\\n",
       "0  User 1         0.0         0.0        3.63        3.65         5.0   \n",
       "1  User 2         0.0         0.0        3.63        3.65         5.0   \n",
       "2  User 3         0.0         0.0        3.63        3.63         5.0   \n",
       "3  User 4         0.0         0.5        3.63        3.63         5.0   \n",
       "4  User 5         0.0         0.0        3.63        3.63         5.0   \n",
       "\n",
       "   Category 6  Category 7  Category 8  Category 9     ...       Category 16  \\\n",
       "0        2.92         5.0        2.35        2.33     ...              0.59   \n",
       "1        2.92         5.0        2.64        2.33     ...              0.59   \n",
       "2        2.92         5.0        2.64        2.33     ...              0.59   \n",
       "3        2.92         5.0        2.35        2.33     ...              0.59   \n",
       "4        2.92         5.0        2.64        2.33     ...              0.59   \n",
       "\n",
       "  Category 17  Category 18  Category 19  Category 20  Category 21  \\\n",
       "0         0.5          0.0          0.5          0.0          0.0   \n",
       "1         0.5          0.0          0.5          0.0          0.0   \n",
       "2         0.5          0.0          0.5          0.0          0.0   \n",
       "3         0.5          0.0          0.5          0.0          0.0   \n",
       "4         0.5          0.0          0.5          0.0          0.0   \n",
       "\n",
       "   Category 22  Category 23  Category 24  Unnamed: 25  \n",
       "0          0.0          0.0          0.0          NaN  \n",
       "1          0.0          0.0          0.0          NaN  \n",
       "2          0.0          0.0          0.0          NaN  \n",
       "3          0.0          0.0          0.0          NaN  \n",
       "4          0.0          0.0          0.0          NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('google_review_ratings.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churches</th>\n",
       "      <th>resorts</th>\n",
       "      <th>beaches</th>\n",
       "      <th>parks</th>\n",
       "      <th>theatres</th>\n",
       "      <th>museums</th>\n",
       "      <th>malls</th>\n",
       "      <th>zoo</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>pubs</th>\n",
       "      <th>...</th>\n",
       "      <th>galleries</th>\n",
       "      <th>dance clubs</th>\n",
       "      <th>pools</th>\n",
       "      <th>gyms</th>\n",
       "      <th>bakeries</th>\n",
       "      <th>spas</th>\n",
       "      <th>cafes</th>\n",
       "      <th>view points</th>\n",
       "      <th>monuments</th>\n",
       "      <th>gardens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.65</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.64</td>\n",
       "      <td>...</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.65</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.65</td>\n",
       "      <td>...</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.63</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.64</td>\n",
       "      <td>...</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.63</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.64</td>\n",
       "      <td>...</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.63</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.64</td>\n",
       "      <td>...</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   churches  resorts  beaches  parks  theatres  museums  malls   zoo  \\\n",
       "0       0.0      0.0     3.63   3.65       5.0     2.92    5.0  2.35   \n",
       "1       0.0      0.0     3.63   3.65       5.0     2.92    5.0  2.64   \n",
       "2       0.0      0.0     3.63   3.63       5.0     2.92    5.0  2.64   \n",
       "3       0.0      0.5     3.63   3.63       5.0     2.92    5.0  2.35   \n",
       "4       0.0      0.0     3.63   3.63       5.0     2.92    5.0  2.64   \n",
       "\n",
       "   restaurants  pubs   ...    galleries  dance clubs  pools  gyms  bakeries  \\\n",
       "0         2.33  2.64   ...         1.74         0.59    0.5   0.0       0.5   \n",
       "1         2.33  2.65   ...         1.74         0.59    0.5   0.0       0.5   \n",
       "2         2.33  2.64   ...         1.74         0.59    0.5   0.0       0.5   \n",
       "3         2.33  2.64   ...         1.74         0.59    0.5   0.0       0.5   \n",
       "4         2.33  2.64   ...         1.74         0.59    0.5   0.0       0.5   \n",
       "\n",
       "   spas  cafes  view points  monuments  gardens  \n",
       "0   0.0    0.0          0.0        0.0      0.0  \n",
       "1   0.0    0.0          0.0        0.0      0.0  \n",
       "2   0.0    0.0          0.0        0.0      0.0  \n",
       "3   0.0    0.0          0.0        0.0      0.0  \n",
       "4   0.0    0.0          0.0        0.0      0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop('User', axis=1 )\n",
    "data = data.drop('Unnamed: 25', axis=1)\n",
    "\n",
    "new_colnames = {'Category 1' : 'churches', 'Category 2' : 'resorts', 'Category 3' : 'beaches', 'Category 4' : 'parks',\n",
    "            'Category 5' : 'theatres', 'Category 6' : 'museums', 'Category 7' : 'malls', 'Category 8' : 'zoo',\n",
    "            'Category 9' : 'restaurants', 'Category 10' : 'pubs', 'Category 11' : 'local services', \n",
    "            'Category 12' : 'pizza_shop', 'Category 13' : 'hotel lodgings', \n",
    "            'Category 14' : 'juice bars', 'Category 15' : 'galleries', 'Category 16' : 'dance clubs',\n",
    "            'Category 17' : 'pools', 'Category 18' : 'gyms', 'Category 19' : 'bakeries', 'Category 20' : 'spas',\n",
    "            'Category 21' : 'cafes', 'Category 22' : 'view points', 'Category 23' : 'monuments', 'Category 24' : 'gardens'}\n",
    "\n",
    "data = data.rename(index=str, columns=new_colnames)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目標:預測 local services的平均評分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5456, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5456 entries, 0 to 5455\n",
      "Data columns (total 24 columns):\n",
      "churches          5456 non-null float64\n",
      "resorts           5456 non-null float64\n",
      "beaches           5456 non-null float64\n",
      "parks             5456 non-null float64\n",
      "theatres          5456 non-null float64\n",
      "museums           5456 non-null float64\n",
      "malls             5456 non-null float64\n",
      "zoo               5456 non-null float64\n",
      "restaurants       5456 non-null float64\n",
      "pubs              5456 non-null float64\n",
      "local services    5456 non-null object\n",
      "pizza_shop        5455 non-null float64\n",
      "hotel lodgings    5456 non-null float64\n",
      "juice bars        5456 non-null float64\n",
      "galleries         5456 non-null float64\n",
      "dance clubs       5456 non-null float64\n",
      "pools             5456 non-null float64\n",
      "gyms              5456 non-null float64\n",
      "bakeries          5456 non-null float64\n",
      "spas              5456 non-null float64\n",
      "cafes             5456 non-null float64\n",
      "view points       5456 non-null float64\n",
      "monuments         5456 non-null float64\n",
      "gardens           5455 non-null float64\n",
      "dtypes: float64(23), object(1)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['local services'] = pd.to_numeric(data['local services'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5454 entries, 0 to 5455\n",
      "Data columns (total 24 columns):\n",
      "churches          5454 non-null float64\n",
      "resorts           5454 non-null float64\n",
      "beaches           5454 non-null float64\n",
      "parks             5454 non-null float64\n",
      "theatres          5454 non-null float64\n",
      "museums           5454 non-null float64\n",
      "malls             5454 non-null float64\n",
      "zoo               5454 non-null float64\n",
      "restaurants       5454 non-null float64\n",
      "pubs              5454 non-null float64\n",
      "local services    5454 non-null float64\n",
      "pizza_shop        5454 non-null float64\n",
      "hotel lodgings    5454 non-null float64\n",
      "juice bars        5454 non-null float64\n",
      "galleries         5454 non-null float64\n",
      "dance clubs       5454 non-null float64\n",
      "pools             5454 non-null float64\n",
      "gyms              5454 non-null float64\n",
      "bakeries          5454 non-null float64\n",
      "spas              5454 non-null float64\n",
      "cafes             5454 non-null float64\n",
      "view points       5454 non-null float64\n",
      "monuments         5454 non-null float64\n",
      "gardens           5454 non-null float64\n",
      "dtypes: float64(24)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[:5000]\n",
    "data_test = data[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_train.drop(['local services'], axis=1)\n",
    "y_train = data_train['local services']\n",
    "y_train = np.array(y_train, dtype=int)\n",
    "x_test = data_test.drop(['local services'], axis=1)\n",
    "y_test = data_test['local services']\n",
    "y_test = np.array(y_test, dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x_train, y_train, x_test, y_test):\n",
    "    train_preds = model.predict(x_train)\n",
    "    test_preds = model.predict(x_test)\n",
    "    train_acc = metrics.accuracy_score(y_train, train_preds)\n",
    "    test_acc = metrics.accuracy_score(y_test, test_preds)\n",
    "    print('Train accuracy: %s' % train_acc)\n",
    "    print('Test accuracy: %s' % test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.716\n",
      "Test accuracy: 0.7731277533039648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression().fit(x_train, y_train)\n",
    "evaluate(clf, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing\n",
    "x_train_NN = preprocessing.normalize(x_train)\n",
    "x_test_NN = preprocessing.normalize(x_test)\n",
    "x_train_NN = x_train_NN*2-1\n",
    "x_test_NN = x_test_NN*2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = 50    # how many neurons in the hidden layer\n",
    "activation = 'relu'  # activation function for hidden layer\n",
    "l2 = 0.1           # regularization - how much we penalize large parameter values\n",
    "learning_rate = 1  # how big our steps are in gradient descent\n",
    "epochs = 50          # how many epochs to train for\n",
    "batch_size = 32      # how many samples to use for each gradient descent update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers, optimizers, regularizers\n",
    "# create a sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# add the hidden layer\n",
    "model.add(layers.Dense(input_dim=23,\n",
    "                       units=hidden_units, \n",
    "                       activation=activation))\n",
    "\n",
    "# add the output layer\n",
    "model.add(layers.Dense(input_dim=hidden_units,\n",
    "                       units=1,\n",
    "                       activation='sigmoid'))\n",
    "\n",
    "# define our loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              # Adam is a kind of gradient descent\n",
    "              optimizer=optimizers.Adam(lr=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "5000/5000 [==============================] - 0s 67us/step - loss: -18.1300 - acc: 0.4012\n",
      "Epoch 2/50\n",
      "5000/5000 [==============================] - 0s 26us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 3/50\n",
      "5000/5000 [==============================] - 0s 26us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 4/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 5/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 6/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 7/50\n",
      "5000/5000 [==============================] - 0s 25us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 8/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 9/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 10/50\n",
      "5000/5000 [==============================] - 0s 25us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 11/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 12/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 13/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 14/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 15/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 16/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 17/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 18/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 19/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 20/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 21/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 22/50\n",
      "5000/5000 [==============================] - 0s 22us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 23/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 24/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 25/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 26/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 27/50\n",
      "5000/5000 [==============================] - 0s 27us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 28/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 29/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 30/50\n",
      "5000/5000 [==============================] - 0s 26us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 31/50\n",
      "5000/5000 [==============================] - 0s 26us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 32/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 33/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 34/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 35/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 36/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 37/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 38/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 39/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 40/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 41/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 42/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 43/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 44/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 45/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 46/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 47/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 48/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 49/50\n",
      "5000/5000 [==============================] - 0s 23us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 50/50\n",
      "5000/5000 [==============================] - 0s 24us/step - loss: -18.2891 - acc: 0.4040\n",
      "5000/5000 [==============================] - 0s 17us/step\n",
      "454/454 [==============================] - 0s 15us/step\n",
      "Training accuracy: 0.404\n",
      "Testing accuracy: 0.5506607929515418\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(x_train_NN, y_train, epochs=50, batch_size=batch_size)\n",
    "\n",
    "# evaluate accuracy\n",
    "train_acc = model.evaluate(x_train_NN, y_train, batch_size=32)[1]\n",
    "test_acc = model.evaluate(x_test_NN, y_test, batch_size=32)[1]\n",
    "print('Training accuracy: %s' % train_acc)\n",
    "print('Testing accuracy: %s' % test_acc)\n",
    "\n",
    "losses = history.history['loss']\n",
    "plt.plot(range(len(losses)), losses, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "準確率不高\n",
    "\n",
    "### 加深層數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 0s 73us/step - loss: -18.1787 - acc: 0.4040\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 0s 33us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 0s 27us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 0s 27us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 0s 30us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 0s 27us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 0s 26us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 0s 25us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 0s 26us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 0s 26us/step - loss: -18.2891 - acc: 0.4040\n",
      "5000/5000 [==============================] - 0s 22us/step\n",
      "454/454 [==============================] - 0s 20us/step\n",
      "Training accuracy: 0.404\n",
      "Testing accuracy: 0.5506607929515418\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# add the hidden layer\n",
    "model.add(layers.Dense(input_dim=23,\n",
    "                       units=64, \n",
    "                       activation=activation))\n",
    "\n",
    "model.add(layers.Dense(input_dim=64,\n",
    "                       units=32, \n",
    "                       activation=activation))\n",
    "\n",
    "\n",
    "# add the output layer\n",
    "model.add(layers.Dense(input_dim=40,\n",
    "                       units=1,\n",
    "                       activation='sigmoid'))\n",
    "\n",
    "# define our loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              # Adam is a kind of gradient descent\n",
    "              optimizer=optimizers.Adam(lr=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# train the parameters\n",
    "history = model.fit(x_train_NN, y_train, epochs=10, batch_size=batch_size)\n",
    "\n",
    "# evaluate accuracy\n",
    "train_acc = model.evaluate(x_train_NN, y_train, batch_size=32)[1]\n",
    "test_acc = model.evaluate(x_test_NN, y_test, batch_size=32)[1]\n",
    "print('Training accuracy: %s' % train_acc)\n",
    "print('Testing accuracy: %s' % test_acc)\n",
    "\n",
    "losses = history.history['loss']\n",
    "plt.plot(range(len(losses)), losses, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "準確率依舊沒有提高\n",
    "\n",
    "因此決定挑幾個跟local service看起來較有關西的feature來做訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(['churches','beaches','parks','juice bars','dance clubs','gyms','bakeries','view points','monuments', 'gardens'], axis=1)\n",
    "x_test = x_test.drop(['churches','beaches','parks','juice bars','dance clubs','gyms','bakeries','view points','monuments', 'gardens'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resorts</th>\n",
       "      <th>theatres</th>\n",
       "      <th>museums</th>\n",
       "      <th>malls</th>\n",
       "      <th>zoo</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>pubs</th>\n",
       "      <th>pizza_shop</th>\n",
       "      <th>hotel lodgings</th>\n",
       "      <th>galleries</th>\n",
       "      <th>pools</th>\n",
       "      <th>spas</th>\n",
       "      <th>cafes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.64</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.64</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.64</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.64</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resorts  theatres  museums  malls   zoo  restaurants  pubs  pizza_shop  \\\n",
       "0      0.0       5.0     2.92    5.0  2.35         2.33  2.64        1.69   \n",
       "1      0.0       5.0     2.92    5.0  2.64         2.33  2.65        1.69   \n",
       "2      0.0       5.0     2.92    5.0  2.64         2.33  2.64        1.69   \n",
       "3      0.5       5.0     2.92    5.0  2.35         2.33  2.64        1.69   \n",
       "4      0.0       5.0     2.92    5.0  2.64         2.33  2.64        1.69   \n",
       "\n",
       "   hotel lodgings  galleries  pools  spas  cafes  \n",
       "0             1.7       1.74    0.5   0.0    0.0  \n",
       "1             1.7       1.74    0.5   0.0    0.0  \n",
       "2             1.7       1.74    0.5   0.0    0.0  \n",
       "3             1.7       1.74    0.5   0.0    0.0  \n",
       "4             1.7       1.74    0.5   0.0    0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6814\n",
      "Test accuracy: 0.7797356828193832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(x_train, y_train)\n",
    "evaluate(clf, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 0s 85us/step - loss: -18.1522 - acc: 0.4014\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 0s 30us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 0s 27us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 0s 28us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 0s 27us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 0s 30us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 0s 28us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 0s 26us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 0s 28us/step - loss: -18.2891 - acc: 0.4040\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 0s 30us/step - loss: -18.2891 - acc: 0.4040\n",
      "5000/5000 [==============================] - 0s 25us/step\n",
      "454/454 [==============================] - 0s 15us/step\n",
      "Training accuracy: 0.404\n",
      "Testing accuracy: 0.5506607929515418\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train_NN = preprocessing.normalize(x_train)\n",
    "x_test_NN = preprocessing.normalize(x_test)\n",
    "x_train_NN = x_train_NN*2-1\n",
    "x_test_NN = x_test_NN*2-1\n",
    "\n",
    "hidden_units = 50    # how many neurons in the hidden layer\n",
    "activation = 'relu'  # activation function for hidden layer\n",
    "l2 = 0.1           # regularization - how much we penalize large parameter values\n",
    "learning_rate = 1  # how big our steps are in gradient descent\n",
    "epochs = 50          # how many epochs to train for\n",
    "batch_size = 32      # how many samples to use for each gradient descent update\n",
    "\n",
    "# create a sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# add the hidden layer\n",
    "model.add(layers.Dense(input_dim=13,\n",
    "                       units=64, \n",
    "                       activation=activation))\n",
    "\n",
    "model.add(layers.Dense(input_dim=64,\n",
    "                       units=32, \n",
    "                       activation=activation))\n",
    "\n",
    "\n",
    "# add the output layer\n",
    "model.add(layers.Dense(input_dim=40,\n",
    "                       units=1,\n",
    "                       activation='sigmoid'))\n",
    "\n",
    "# define our loss function and optimizer\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              # Adam is a kind of gradient descent\n",
    "              optimizer=optimizers.Adam(lr=learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# train the parameters\n",
    "history = model.fit(x_train_NN, y_train, epochs=10, batch_size=batch_size)\n",
    "\n",
    "# evaluate accuracy\n",
    "train_acc = model.evaluate(x_train_NN, y_train, batch_size=32)[1]\n",
    "test_acc = model.evaluate(x_test_NN, y_test, batch_size=32)[1]\n",
    "print('Training accuracy: %s' % train_acc)\n",
    "print('Testing accuracy: %s' % test_acc)\n",
    "\n",
    "losses = history.history['loss']\n",
    "plt.plot(range(len(losses)), losses, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
